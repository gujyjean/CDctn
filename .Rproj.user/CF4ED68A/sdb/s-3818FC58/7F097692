{
    "collab_server" : "",
    "contents" : "# ========================================================\n# Note that this is only a trial version.\n# No documentation yet\n# ========================================================\n\n#' @useDynLib CDctn\n# #' @importFrom Rcpp sourceCpp\nNULL\n\n# Generate the distribution of in-degrees given the maximum in-degree and the total number of edges in a graph.\n# maxdeg: maximum in-degree; node: the number of nodes; nedge: the total number of edges\ndegreeG <- function(maxdeg, node, nedge) {\n    degree.dist <- rep(0,maxdeg+1)\n    nx <- node; nex <- nedge\n    if(maxdeg>=2) {\n        for (i in maxdeg:2) {\n            lower <- max(0, ceiling(nex-(nx-i/2)*(i-1)))\n            upper <- min(nx-i, floor(nex/i))\n            if(lower<upper)    {degree.dist[i+1] <- sample(lower:upper,1)}\n            else if(lower==upper)    {degree.dist[i+1] <- lower}\n            else  {next}\n            nx <- nx-degree.dist[i+1]\n            nex <- nex-i*degree.dist[i+1]\n            if(nx<=0 || nex<0)    stop(\"Error\")\n        }\n    }\n    if (nx>=(nex+1))   degree.dist[2] <- nex\n    else  stop(\"Error!\")\n    degree.dist[1] <- node-sum(degree.dist[2:(maxdeg+1)])\n    return(degree.dist)\n}\n\n\n\n# Generate DAGs given the maximum in-degree and the total number of edges.\n\n#' Generate DAGs given the maximum in-degree and the total number of edges\n#' @param maxdeg maximum in-degree\n#' @param node the number of nodes\n#' @param nedge the total number of edges\n#' @return A list of 4.\n#' \\item{ordex}{parent set matrix, of dimension maxdeg*node.\n#'              Each nonzero entry in column j lists one parent of node j.\n#'              The parents\tof node j are sorted in ascending order.}\n#' \\item{trueG}{the adjacency matrix of the generated DAG}\n#' \\item{ts}{one topological sort of the generated DAG}\n#' \\item{degree.dist}{the distribution of in-degrees of all nodes.\n#'                    Element j lists the number of nodes whose in-degree equals j-1}\n#' @export\nGGen <- function(maxdeg, node, nedge) {\n\n\tordex <- matrix(0, maxdeg, node)\t\t# matrix listing the parents of each node (similar to the adjacency list)\n\tts <- sample(1:node)\t\t\t\t\t# topological sort\n\tdegree.dist <- degreeG(maxdeg, node, nedge)\n\tindegree <- rep(0,node)\t\t\t\t\t# indegree is matched to ts\n\tind <- rep(TRUE, node)\n\tfor (i in (maxdeg+1):1) {\n\t\tif(degree.dist[i]>0) {\n\t\t\tcandidate <- (i:node)[ind[i:node]]\n\t\t\tif(length(candidate)==1)   {\n\t\t\t\tindegree[candidate] <- (i-1)\n\t\t\t\tind[candidate] <- FALSE\n\t\t\t}\n\t\t\telse  {\n\t\t\t\tpos <- sample(candidate,degree.dist[i])\n\t\t\t\tindegree[pos] <- (i-1)\n\t\t\t\tind[pos] <- FALSE\n\t\t\t}\n\t\t}\n\t}\n\tfor (i in 1:node) {\n\t\tnp <- indegree[i]\n\t\tif(np==0)   next\n\t\telse if(i==2)    ordex[1,ts[i]] <- ts[1]\n\t\telse   {\n\t\t\tpa <- sample(ts[1:(i-1)], np)\n\t\t\tordex[1:np,ts[i]] <- sort(pa)\n\t\t}\n\t}\n\ttrueG <- matrix(0,node,node)\n\tfor (i in 1:node) {\n\t\ttrueG[ordex[ordex[,i]!=0,i],i] <- 1\n\t}\n\n\treturn(list(ordex=ordex, trueG=trueG, ts=ts, degree.dist=degree.dist))\n\n}\n\n\n\n# Generate Gaussian data from DAGs using the outputs from the function GGen as the inputs.\n# coeff: the beta coefficient; noi: the number of interventions/data blocks; nobs: the number of interventional samples in each data block\n\n#' Generate Gaussian interventional data from DAGs\n#' @param ordex parent set matrix, of dimension maxdeg*node. See GGen\n#' @param ts one topological sort of the DAG. See GGen\n#' @param coeff the beta value used to generate Gaussian samplesb$ob\n#' @param noi the number of nodes that have interventional smaples\n#' (i.e., the number of data blocks). Each data block contains\n#' interventional samples where one particular node is experimentally manipulated\n#' @param nobs the sample size of each data block\n#' @return A list of 3\n#' \\item{data}{data matrix of dimension (nobs*noi)*node}\n#' \\item{ivn}{the vector of nodes that have interventional samples}\n#' \\item{obslist}{list of indices of observational samples for each node\n#'                (excluding interventional samples).\n#'                The list has length equal to node}\n#' @export\nDatGen <- function(ordex, ts, coeff, noi, nobs) {\n\n\tmaxdeg <- nrow(ordex); node <- ncol(ordex)\n\tbeta <- matrix(coeff, maxdeg, node)\n\tivn <- sort(sample(1:node, noi))\t\t\t\t\t# nodes that have interventional data\n\tfX <- matrix(rnorm(noi*nobs,0,1),ncol=noi)\n\tdata <- .Call(\"datGenC\", as.integer(node),as.integer(maxdeg),as.integer(ordex),as.integer(ts),\n                     as.integer(noi),as.integer(nobs),as.integer(ivn),as.double(fX),as.double(beta))\n\tdata <- matrix(data, ncol=node, byrow=TRUE)\n\tobslist <- list()\t\t\t\t\t\t\t\t\t# list of indices of observational samples for each node (excluding interventional samples)\n\tkdex <- 0\n\tfor (k in 1:node) {\n\t\tif (any((k-ivn)==0)) {\n\t\t\tkdex <- kdex+1\n\t\t\tobslist[[k]] <- (1:nrow(data))[-((nobs*kdex-nobs+1):(nobs*kdex))]\n\t\t} else {\n\t\t\tobslist[[k]] <- 1:nrow(data)\n\t\t}\n\t}\n\treturn(list(data=data, ivn=ivn, obslist=obslist))\n\n}\n\n\n\n# Compute solutions to the penalized likelihood problem on a grid of lambdas.\n\n#' compute solutions to the penalized likelihood estimation\n#' problem on a grid of lambdas\n#' @param node the number of nodes of the DAG\n#' @param data the data matrix of dimension (nobs*noi)*node. See DatGen\n#' @param obslist list of observational samples. See DatGen\n#' @param eorder matrix indicating the order to cycle through\n#'        the pair of nodes in the CD algorithm. nrow of the matrix is\n#'        0.5*node*(node-1), and ncol of the matrix is 2.\n#'        Each row is a pair of nodes\n#' @param fmlam the ratio of lambda_min/lambda_max\n#' @param nlam the number of lambda values\n#' @param eps threshold of convergence for the CD algorithm\n#' @param beta the initial coefficient matrix B^0.\n#'        If missing, will assume to be all zero matrix\n#' @param lambda the sequence of lambda values to be used.\n#'        If missing, it will be constructed from data using fmlam and nlam.\n#' @param gamma the exponent in the weights for the adaptive lasso penalty\n#' @param lowerbound the constant used to truncate the weights\n#'        for the adaptive lasso penalty\n#' @return A list of 2\n#' \\item{coef}{matrix of estimated coefficients, of dimension nlam*(node^2).\n#'             Each row contains the estimate of the coefficient\n#'             matrix (stored as a vector) at a single value of lambda}\n#' \\item{lambda}{the sequence of lambda values used}\n#' @export\ncdpathC <- function(node, data, obslist, eorder, fmlam=0.001, nlam=50, eps=1e-4, beta, lambda, gamma=0.15, lowerbound=1e-4)  {\n\n\targind1 <- missing(lambda); argind2 <- missing(beta)\n\n    obs.leng <- sapply(obslist, length)\n    ncoef <- node*node\n\tsigma <- rep(0,node)\n    xlist <- list()\n    ylist <- list()\n\tNormx <- NULL\n\tinverseWeights <- matrix(0,node,node)\n\tscale.factor <- NULL\n    for (i in 1:node) {\n        xtemp <- scale(data[obslist[[i]], ], TRUE, FALSE)\n\t\tnormx <- sqrt(colSums(xtemp^2))\n        xtemp <- scale(xtemp, FALSE, normx)\n\t\tscale.factor <- c(scale.factor,normx[i]/normx)\n\n\t\tinverseWeights[-i,i] <- W <- pmax(abs(lm(xtemp[,i]~xtemp[,-i]-1)$coef),lowerbound)^gamma\t\t# compute weights for the adaptive lasso\n\t\txtemp[,-i] <- xtemp[,-i]*rep(W,rep(obs.leng[i],node-1))            \t\t\t\t\t\t\t\t# rescale x for the adaptive lasso\n\n\t\tNormx <- c(Normx, colSums(xtemp^2))\n        ylist[[i]] <- xtemp[,i]\n\t\tsigma[i] <- sum(xtemp[,i]^2)/obs.leng[i]\n        xtemp[, i] <- 0\n        xlist[[i]] <- xtemp\n    }\n    re.prod <- .Call(\"prodG\",as.integer(node),xlist,ylist,as.integer(obs.leng))\n    inprod <- re.prod$inprod                            # inner products of each feature with y initially\n    feature.prod <- re.prod$fprod                     \t# inner products between features\n\n    if(argind1) {\n        maxtmp1 <- max(abs(inprod)/rep(sigma,rep(node,node)))\n\t\tmax.lam <- 7*maxtmp1\n        min.lam <- fmlam*max.lam\n        lambda <- exp(seq(log(max.lam), log(min.lam), log(fmlam)/(nlam-1)))\n    }\n    if(argind2)    beta <- matrix(0, node, node)\n\n\n\tnorm <- penalty <- rep(0,node)\n\tfor (i in 1:node) {\n        residual <- ylist[[i]]-xlist[[i]] %*% beta[,i]\n        norm[i] <- sum(residual^2)\n\t\tpenalty[i] <- lambda[1]*sum(abs(beta[,i]))\n    }\n    rsq <- sum(obs.leng*log(sigma)/2)+sum(norm/(2*sigma))+sum(penalty)\n\n\teorleng <- nrow(eorder)\n    eorder <- t(eorder)\n    result <- .C(\"CDGridR\", as.integer(node), as.double(beta), as.double(lambda), as.double(inprod), as.double(feature.prod),\n              as.integer(eorder), as.double(rsq), as.double(eps), coef=double(nlam*ncoef), RSQ=double(nlam), ITER=integer(nlam), as.integer(nlam-1),\n\t\t\t  as.double(sigma), sig=double(nlam*node), as.double(norm), as.integer(obs.leng), as.integer(eorleng))\n    coef <- matrix(result$coef*rep(inverseWeights,nlam), ncol=ncoef, byrow=TRUE)\n\n\n\n\n\t# use new weights to recompute the solutions\n\tinverseWeights <- matrix(abs(coef[nlam,])^gamma,ncol=node)\n    for (i in 1:node) {\n        xtemp <- scale(data[obslist[[i]], ], TRUE, FALSE)\n\t\tnormx <- sqrt(colSums(xtemp^2))\n        xtemp <- scale(xtemp, FALSE, normx)\n\n\t\txtemp[,-i] <- xtemp[,-i]*rep(inverseWeights[-i,i],rep(obs.leng[i],node-1))\n\n        ylist[[i]] <- xtemp[,i]\n\t\tsigma[i] <- sum(xtemp[,i]^2)/obs.leng[i]\n        xtemp[, i] <- 0\n        xlist[[i]] <- xtemp\n    }\n\tre.prod <- .Call(\"prodG\",as.integer(node),xlist,ylist,as.integer(obs.leng))\n    inprod <- re.prod$inprod\n    feature.prod <- re.prod$fprod\n\n\tif(argind1) {\n        maxtmp1 <- max(abs(inprod)/rep(sigma,rep(node,node)))\n\t\tmax.lam <- 7*maxtmp1\n        min.lam <- fmlam*max.lam\n        lambda <- exp(seq(log(max.lam), log(min.lam), log(fmlam)/(nlam-1)))\n    }\n    if(argind2)    beta <- matrix(0, node, node)\n\n\tnorm <- penalty <- rep(0,node)\n\tfor (i in 1:node) {\n        residual <- ylist[[i]]-xlist[[i]] %*% beta[,i]\n        norm[i] <- sum(residual^2)\n\t\tpenalty[i] <- lambda[1]*sum(abs(beta[,i]))\n    }\n    rsq <- sum(obs.leng*log(sigma)/2)+sum(norm/(2*sigma))+sum(penalty)\n\n    result <- .C(\"CDGridR\", as.integer(node), as.double(beta), as.double(lambda), as.double(inprod), as.double(feature.prod),\n              as.integer(eorder), as.double(rsq), as.double(eps), coef=double(nlam*ncoef), RSQ=double(nlam), ITER=integer(nlam), as.integer(nlam-1),\n\t\t\t  as.double(sigma), sig=double(nlam*node), as.double(norm), as.integer(obs.leng), as.integer(eorleng))\n    coef <- matrix(result$coef*rep(inverseWeights,nlam), ncol=ncoef, byrow=TRUE)\n\n\n\n\n\tcoef <- coef*rep(scale.factor,rep(nlam,ncoef))\n    return(list(coef=coef, lambda=lambda))\n\n}\n\n\n\n# Compute the negative log-likelihood using unpenalized coefficients.\n\n#' compute the negative log-likelihood using unpenalized coefficients\n#' @param node the number of nodes of the DAG\n#' @param G the adjacency matrix of the DAG\n#' @param data the data matrix of dimension (nobs*noi)*node. See DatGen\n#' @param obslist list of observational samples. See DatGen\n#' @return pLog, the negative log-likelihood\n#' @export\nplog <- function(node, G, data, obslist)  {\n\n   obs.leng <- sapply(obslist, length)\n   RSS <- rep(0,node)\n   for (i in 1:node) {\n\t\tpa <- which(G[,i]!=0)\n        xtemp <- scale(data[obslist[[i]], ], TRUE, FALSE)\n        if(length(pa)>0) {\n\t\t\tRSS[i] <- sum(lm(xtemp[,i]~xtemp[,pa]-1)$res^2)\n\t\t} else {\n\t\t    RSS[i] <- sum(xtemp[,i]^2)\n\t\t}\n   }\n   pLog <- sum(obs.leng*log(RSS/obs.leng)/2)+sum(obs.leng/2)\n   return(pLog)\n\n}\n\n\n",
    "created" : 1458861760376.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2689974044",
    "id" : "7F097692",
    "lastKnownWriteTime" : 1458885964,
    "path" : "~/Documents/STAT-COURSE/qualify/CDctn/CDctn/R/DAG.r",
    "project_path" : "R/DAG.r",
    "properties" : {
    },
    "relative_order" : 4,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}