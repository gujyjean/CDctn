{
    "collab_server" : "",
    "contents" : "###########################################################################################################################################\n# \tRun the following scripts to produce the CD result using one data set from a randomly generated DAG that has p = 50 and beta = 0.5.\n#\tRun \"R CMD BATCH sample.r\" in the current folder from the command line.\n#\n#\tBefore running the codes, you need to\n#\t1. Create shared libraries by running\n#   \t$ R CMD SHLIB Basic.c\n#   \t$ R CMD SHLIB CD.c\n#\t2. Load both shared libraries into R using dyn.load.\n#\t3. Source R codes in \"DAG.r\" by using source.\n#\n#\tNote: \tFor large networks, if the dimension of the data set is large, the program consumes a fair amount of memory. This problem\n#\t\t\tnormally occurs for DAGs with 200 nodes in our experiments, where memory consumption exceeds 2.5GB if the data set has\n#\t\t\t6,000 samples. Thus, our current implementation should not be applied to large data sets generated from DAGs with more than\n#\t\t\t200 nodes.\n###########################################################################################################################################\n\n# source DAG.r. Replace ... with the directory of the corresponding file.\nsource(\"./DAG.r\")\n\n# load shared libraries (.so under unix-like or .dll under windows). Replace ... with the directory of the corresponding files.\ndyn.load(\"./Basic.so\")\ndyn.load(\"./CD.so\")\n\n###########################################################################################################################################\n# set all necessary function arguments. See readme for details.\n\n# set arguments for function \"GGen\".\nnode <- 50\nmaxdeg <- 4\nnedge <- 2*node\n\n# set arguments for function \"DatGen\". The total sample size is determined by (noi*nobs).\ncoeff <- 0.5\nnoi <- node\nnobs <- 120\n\n# set arguments for function \"cdpathC\".\n# we usually set \"Gamma\" to be around 0.15. We occasionally use Gamma = 0.5 when both \"node\" and \"coeff\" are large.\n# change \"fmlam\" and \"nlam\" to obtain a longer sequence of lambda values on a finer grid.\nfmlam <- 0.001\nnlam <- 50\neps <- 1e-4\nGamma <- 0.15\nlowerbound <- 1e-4\neorder <- which(matrix(TRUE, node, node),arr.ind=TRUE)[,c(2,1)]\neorder <- matrix(eorder[which(eorder[,2]>eorder[,1]),], ncol=2)\n###########################################################################################################################################\n\n\n\n\n\n\n# generate one DAG and save. You can modify the argument \"file\" to specify the directory for saving the output.\notglist <- GGen(maxdeg, node, nedge)\nwrite.table(otglist$trueG, file=\"dag.txt\", sep=\" \", row.names=FALSE, col.names=FALSE)\n\n# generate one interventional data set from the DAG. You can modify the argument \"file\" to specify the directory for saving the output.\ndata.list <- DatGen(otglist$ordex, otglist$ts, coeff, noi, nobs)\nwrite.table(data.list$data, file=\"data.txt\", sep=\" \", row.names=FALSE, col.names=FALSE)\nwrite.table(t(data.list$ivn), file=\"ivn.txt\", sep=\" \", row.names=FALSE, col.names=FALSE)\n\n# run the CD algorithm.\n# note: function \"cdpathC\" runs the CD algorithm twice. See \"Section 3 Asymptotic Properties\" of the paper for discussion.\ncoefficient <- cdpathC(node, data.list$data, data.list$obslist, eorder=eorder, fmlam=fmlam, nlam=nlam, eps=eps, gamma=Gamma, lowerbound=lowerbound)$coef\n\n\n\n\n\n\n# create a matrix to store results.\nstat <- matrix(0, nrow=nlam, ncol=6)\ncolnames(stat) <- c(\"predicted\",\"expected\",\"reversed\",\"missed\",\"fal.pos\",\"logL\")\n\n# evaluate the estimated DAGs against the true DAG.\ntrueG <- otglist$trueG\nfor (j in 1:nlam) {\n    mg <- matrix(0,node,node)\n    mg[coefficient[j,]!=0] <-1\n\tstat[j,1] <- predicted <- length(mg[mg==1])\t\t\t\t\t\t\t\t\t# compute the number of predicted edges\n    stat[j,2] <- expected <- length(mg[(mg==trueG) & (mg==1)])\t\t\t\t\t# compute the number of expected edges\n    stat[j,3] <- reversed <- length(mg[(mg-t(trueG)==0) & (mg==1)])\t\t\t\t# compute the number of reversed edges\n    stat[j,4] <- missed <- length(which((mg==0) & (trueG==1) & (t(mg)==0)))\t\t# compute the number of missed edges\n\tstat[j,5] <- fal.pos <- predicted-expected-reversed\t\t\t\t\t\t\t# compute the number of false positive edges\n\tstat[j,6] <- -plog(node, mg, data.list$data, data.list$obslist)\t\t\t\t# compute the log-likelihood\n}\n\n# save results to a file. You can modify the argument \"file\" to specify the directory for saving the output.\nwrite.table(stat, file=\"CDstat.txt\", sep=\" \", row.names=FALSE, col.names=TRUE)\n\n\n",
    "created" : 1458862137658.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2937612651",
    "id" : "55A2B89B",
    "lastKnownWriteTime" : 1457475868,
    "path" : "~/Documents/STAT-COURSE/qualify/CDctn/sample.r",
    "project_path" : null,
    "properties" : {
    },
    "relative_order" : 4,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}